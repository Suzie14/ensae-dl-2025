{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST with an MLP, from scratch\n",
    "\n",
    "# - Step 1: build an MLP from scratch to solve MNIST. Question set: https://fleuret.org/dlc/materials/dlc-practical-3.pdf\n",
    "# - Step 2: debug your network with backprop ninja and a reference implementation using torch's .backward()\n",
    "# - Step 3: build the same MLP but will full pytorch code (nn.Linear, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = load_data(one_hot_labels = True, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11ca724a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_input[4].view((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy (preds, targets):\n",
    "    \"\"\" Computes the accuracy between predictions and targets. Data is expected to be one-hot encoded. \"\"\"\n",
    "    _, idx1 = torch.max(preds, dim=1)\n",
    "    _, idx2 = torch.max(targets, dim=1)\n",
    "    d = idx1 == idx2\n",
    "    return d.int().float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test\n",
    "# this cell should return 0.75\n",
    "preds = torch.zeros((4,7))\n",
    "preds[0,1] = 1\n",
    "preds[1,4] = 1\n",
    "preds[2,2] = 1\n",
    "preds[3,6] = 1\n",
    "targets = torch.zeros((4,7))\n",
    "targets[0,1] = 1\n",
    "targets[1,4] = 1\n",
    "targets[2,2] = 1\n",
    "targets[3,2] = 1\n",
    "compute_accuracy(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def dsigma(x):\n",
    "    return 1 - torch.pow(torch.tanh(x), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(v, t):\n",
    "    return torch.sum(torch.pow(t - v, 2))\n",
    "\n",
    "def dloss(v, t):\n",
    "    return 2 * (v - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3267,  0.5161,  0.4194, -1.4781,  3.9586, -3.8231],\n",
       "        [ 4.7482, -0.0533,  0.4343,  1.9430, -0.8863, -3.9754],\n",
       "        [ 3.1992,  2.3537,  0.6569, -0.9089,  1.9316, -4.6015]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "v = torch.randn((3, 6), dtype=torch.float32)\n",
    "t = torch.randn((3, 6), dtype=torch.float32)\n",
    "l=loss(v,t)\n",
    "dloss(v,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply targets by 0.9 to be in the range of tanh\n",
    "train_target *= 0.9\n",
    "test_target *= 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Backprop ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "# DO NOT MODIFY IT\n",
    "#\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "w1 = torch.randn((784, 50))\n",
    "b1 = torch.randn((50,))\n",
    "w2 = torch.randn((50, 10))\n",
    "b2 = torch.randn((10,))\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10]), tensor(43.2825, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = train_input[:5]\n",
    "y1 = train_target[:5]\n",
    "z1 = x1 @ w1 + b1\n",
    "h1 = sigma(z1)\n",
    "z2 = h1 @ w2 + b2\n",
    "h2 = sigma(z2)\n",
    "l = loss(h2, y1)\n",
    "h2.shape, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=43.282527923583984\n"
     ]
    }
   ],
   "source": [
    "# Force pytorch to retain grade for intermediate nodes and reset grad for parameters\n",
    "# DO NOT MODIFY THIS CODE\n",
    "#\n",
    "others = [h2,z2,h1,z1]\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in others:\n",
    "    t.retain_grad()\n",
    "l.backward()\n",
    "print(f'loss={l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "z2              | exact: False | approximate: True  | maxdiff: 1.6298145055770874e-09\n",
      "w2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h1              | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
      "z1              | exact: False | approximate: True  | maxdiff: 4.423782229423523e-09\n",
      "w1              | exact: False | approximate: True  | maxdiff: 5.960464477539063e-08\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# here we compare our gradient to the reference gradient computed by pytorch\n",
    "dl = 1.0\n",
    "dh2 = dloss(h2, y1) * dl\n",
    "cmp('h2',dh2,h2)\n",
    "dz2 = dsigma(z2) * dh2\n",
    "cmp('z2',dz2, z2)\n",
    "dw2 = h1.T @ dz2\n",
    "cmp('w2',dw2, w2)\n",
    "db2 = dz2.sum(axis=0, keepdim=True)\n",
    "cmp('b2',db2, b2)\n",
    "dh1 = dz2 @ w2.T\n",
    "cmp('h1',dh1, h1)\n",
    "dz1 = dsigma(z1) * dh1\n",
    "cmp('z1', dz1, z1)\n",
    "dw1 = x1.T @ dz1\n",
    "cmp('w1', dw1, w1)\n",
    "db1 = dz1.sum(axis=0, keepdim=True)\n",
    "cmp('b1', db1, b1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "with torch.no_grad():\n",
    "    w1 += -lr * dw1\n",
    "    b1 += -lr * db1.squeeze()\n",
    "    w2 += -lr * dw2\n",
    "    b2 += -lr * db2.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.282527923583984"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = loss(h2, y1)\n",
    "l.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that we've checked our gradients are correct, we can implement the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{aligned}\n",
    "z_1 &= x \\, w_1 + b_1, \\quad &z_2 &= h_1 \\, w_2 + b_2,\\\\[1mm]\n",
    "h_1 &= \\tanh(z_1), \\quad &h_2 &= \\tanh(z_2).\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "L = \\|h_2 - y_1\\|^2,\n",
    "\\end{aligned}\n",
    "\n",
    "so that\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L}{\\partial h_2} = 2\\,(h_2 - y_1).\n",
    "\\end{aligned}\n",
    "\n",
    "**For layer 2:**\n",
    "\n",
    "- **Output gradient:**\n",
    "  \\begin{aligned}\n",
    "  dh_2 = 2\\,(h_2 - y_1).\n",
    "  \\end{aligned}\n",
    "\n",
    "- **Backpropagation through tanh:**\n",
    "  \\begin{aligned}\n",
    "  dz_2 = \\Bigl( 1 - \\tanh(z_2)^2 \\Bigr) \\odot dh_2.\n",
    "  \\end{aligned}\n",
    "\n",
    "- **Gradients for layer 2 parameters:**\n",
    "  \\begin{aligned}\n",
    "  dw_2 = h_1^\\top\\,dz_2, \\quad db_2 = \\sum dz_2.\n",
    "  \\end{aligned}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(w1, b1, w2, b2, x):\n",
    "    z1 = x @ w1 + b1 \n",
    "    h1 = torch.tanh(z1)\n",
    "    z2 = h1 @ w2 + b2 \n",
    "    h2 = torch.tanh(z2) \n",
    "    return z1, h1, z2, h2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(w1, b1, w2, b2, x1, y1, h2, z2, h1, z1):\n",
    "    dl = 1.0\n",
    "    dh2 = 2 * (h2 - y1) * dl\n",
    "    dz2 = (1 - torch.tanh(z2)**2) * dh2\n",
    "    dw2 = h1.T @ dz2\n",
    "    db2 = dz2.sum(axis=0, keepdim=True)\n",
    "    dh1 = dz2 @ w2.T\n",
    "    dz1 = (1 - torch.tanh(z1)**2) * dh1\n",
    "    dw1 = x1.T @ dz1\n",
    "    db1 = dz1.sum(axis=0, keepdim=True)\n",
    "    return dw1, db1, dw2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w1, b1, w2, b2, dw1, db1, dw2, db2, lr):\n",
    "    with torch.no_grad():\n",
    "        w1 += -lr * dw1\n",
    "        b1 += -lr * db1\n",
    "        w2 += -lr * dw2\n",
    "        b2 += -lr * db2\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    \"\"\" init a network \"\"\"\n",
    "    d_in, d_hidden, d_out = 784, 50, 10 \n",
    "\n",
    "    w1 = torch.randn(d_in, d_hidden, dtype=torch.float32)\n",
    "    b1 = torch.zeros(1, d_hidden, dtype=torch.float32)\n",
    "    w2 = torch.randn(d_hidden, d_out, dtype=torch.float32)\n",
    "    b2 = torch.zeros(1, d_out, dtype=torch.float32)\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init()\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training loop\n",
    "torch.set_printoptions(linewidth=200)\n",
    "def train(w1, b1, w2, b2):\n",
    "    lossi = []\n",
    "    for step in range(10000):\n",
    "        xb = train_input\n",
    "        yb = train_target\n",
    "        num_samples = xb.shape[0]\n",
    "        # forward\n",
    "        z1, h1, z2, h2 = forward(w1, b1, w2, b2, xb)\n",
    "        lsi = loss(h2, yb)\n",
    "        # backward\n",
    "        dw1, db1, dw2, db2 = backward(w1, b1, w2, b2, xb, yb, h2, z2, h1, z1)\n",
    "        # update\n",
    "        lr = 0.1 / num_samples if step < 5000 else 0.01 / num_samples\n",
    "        w1, b1, w2, b2 = update(w1, b1, w2, b2, dw1, db1, dw2, db2, lr)\n",
    "        if step % 100 == 0: print(f'step = {step}, loss = {lsi}')\n",
    "        lossi.append(lsi.item())\n",
    "    # compute accuracy\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, train_input)\n",
    "    train_accuracy = compute_accuracy(preds, train_target)\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, test_input)\n",
    "    test_accuracy = compute_accuracy(preds, test_target)\n",
    "    print(f'{train_accuracy=}')\n",
    "    print(f'{test_accuracy=}')\n",
    "    return lossi\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0, loss = 9327.875\n",
      "step = 100, loss = 8072.5048828125\n",
      "step = 200, loss = 7631.78857421875\n",
      "step = 300, loss = 7338.3525390625\n",
      "step = 400, loss = 7142.48095703125\n",
      "step = 500, loss = 6997.7744140625\n",
      "step = 600, loss = 6817.400390625\n",
      "step = 700, loss = 6718.619140625\n",
      "step = 800, loss = 6570.3984375\n",
      "step = 900, loss = 6484.91015625\n",
      "step = 1000, loss = 6304.37060546875\n",
      "step = 1100, loss = 6150.9775390625\n",
      "step = 1200, loss = 5986.3525390625\n",
      "step = 1300, loss = 5798.447265625\n",
      "step = 1400, loss = 5585.392578125\n",
      "step = 1500, loss = 5269.263671875\n",
      "step = 1600, loss = 4493.4150390625\n",
      "step = 1700, loss = 3937.642822265625\n",
      "step = 1800, loss = 3590.25341796875\n",
      "step = 1900, loss = 2889.75048828125\n",
      "step = 2000, loss = 2553.044921875\n",
      "step = 2100, loss = 2181.40673828125\n",
      "step = 2200, loss = 2084.495361328125\n",
      "step = 2300, loss = 1960.607177734375\n",
      "step = 2400, loss = 1721.9228515625\n",
      "step = 2500, loss = 1213.4764404296875\n",
      "step = 2600, loss = 1054.1436767578125\n",
      "step = 2700, loss = 927.4277954101562\n",
      "step = 2800, loss = 738.874267578125\n",
      "step = 2900, loss = 553.792236328125\n",
      "step = 3000, loss = 513.5015869140625\n",
      "step = 3100, loss = 494.77947998046875\n",
      "step = 3200, loss = 482.10504150390625\n",
      "step = 3300, loss = 473.5055847167969\n",
      "step = 3400, loss = 466.96856689453125\n",
      "step = 3500, loss = 461.0173034667969\n",
      "step = 3600, loss = 456.2262878417969\n",
      "step = 3700, loss = 452.170654296875\n",
      "step = 3800, loss = 448.9107666015625\n",
      "step = 3900, loss = 446.87548828125\n",
      "step = 4000, loss = 445.15240478515625\n",
      "step = 4100, loss = 443.5867614746094\n",
      "step = 4200, loss = 441.5838623046875\n",
      "step = 4300, loss = 439.6695861816406\n",
      "step = 4400, loss = 438.103271484375\n",
      "step = 4500, loss = 436.48187255859375\n",
      "step = 4600, loss = 433.486572265625\n",
      "step = 4700, loss = 430.6831970214844\n",
      "step = 4800, loss = 428.0257568359375\n",
      "step = 4900, loss = 426.052734375\n",
      "step = 5000, loss = 424.6649169921875\n",
      "step = 5100, loss = 403.1278076171875\n",
      "step = 5200, loss = 402.9939270019531\n",
      "step = 5300, loss = 402.8624267578125\n",
      "step = 5400, loss = 402.7321472167969\n",
      "step = 5500, loss = 402.60284423828125\n",
      "step = 5600, loss = 402.4742431640625\n",
      "step = 5700, loss = 402.34619140625\n",
      "step = 5800, loss = 402.2186584472656\n",
      "step = 5900, loss = 402.091552734375\n",
      "step = 6000, loss = 401.9648742675781\n",
      "step = 6100, loss = 401.8385314941406\n",
      "step = 6200, loss = 401.712646484375\n",
      "step = 6300, loss = 401.5872802734375\n",
      "step = 6400, loss = 401.46240234375\n",
      "step = 6500, loss = 401.338134765625\n",
      "step = 6600, loss = 401.21453857421875\n",
      "step = 6700, loss = 401.09173583984375\n",
      "step = 6800, loss = 400.96966552734375\n",
      "step = 6900, loss = 400.8482666015625\n",
      "step = 7000, loss = 400.7276611328125\n",
      "step = 7100, loss = 400.6077880859375\n",
      "step = 7200, loss = 400.4885559082031\n",
      "step = 7300, loss = 400.3699035644531\n",
      "step = 7400, loss = 400.2518615722656\n",
      "step = 7500, loss = 400.13433837890625\n",
      "step = 7600, loss = 400.0173034667969\n",
      "step = 7700, loss = 399.9007873535156\n",
      "step = 7800, loss = 399.7847900390625\n",
      "step = 7900, loss = 399.6692810058594\n",
      "step = 8000, loss = 399.55426025390625\n",
      "step = 8100, loss = 399.43975830078125\n",
      "step = 8200, loss = 399.3257141113281\n",
      "step = 8300, loss = 399.212158203125\n",
      "step = 8400, loss = 399.09912109375\n",
      "step = 8500, loss = 398.9866027832031\n",
      "step = 8600, loss = 398.8744812011719\n",
      "step = 8700, loss = 398.7626953125\n",
      "step = 8800, loss = 398.65130615234375\n",
      "step = 8900, loss = 398.54022216796875\n",
      "step = 9000, loss = 398.4293518066406\n",
      "step = 9100, loss = 398.318603515625\n",
      "step = 9200, loss = 398.2079162597656\n",
      "step = 9300, loss = 398.09716796875\n",
      "step = 9400, loss = 397.986328125\n",
      "step = 9500, loss = 397.87518310546875\n",
      "step = 9600, loss = 397.763671875\n",
      "step = 9700, loss = 397.6517333984375\n",
      "step = 9800, loss = 397.5392150878906\n",
      "step = 9900, loss = 397.4260559082031\n",
      "train_accuracy=0.8360000252723694\n",
      "test_accuracy=0.5720000267028809\n"
     ]
    }
   ],
   "source": [
    "lossi = train(w1, b1, w2, b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x128575180>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reference implementation using pytorch's .backward()\n",
    "Nothing to do in Step 2, this code is provided for you as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init()\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code\n",
    "torch.set_printoptions(linewidth=200)\n",
    "import torch.nn as F\n",
    "\n",
    "def train(w1, b1, w2, b2):\n",
    "    lossi = []\n",
    "    for step in range(10000):\n",
    "        xb = train_input\n",
    "        yb = train_target\n",
    "        num_samples = xb.shape[0]\n",
    "        # forward\n",
    "        z1, h1, z2, h2 = forward(w1, b1, w2, b2, xb)\n",
    "        xloss = F.MSELoss()\n",
    "        lsi = xloss(h2, yb) * yb.nelement()\n",
    "        # backward\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        lsi.backward()\n",
    "        # update\n",
    "        lr = 0.1 / num_samples\n",
    "        for p in parameters:\n",
    "            p.data += -lr * p.grad\n",
    "        if step % 100 == 0: print(f'step = {step}, loss = {lsi}')\n",
    "        lossi.append(lsi.item())\n",
    "    # compute accuracy\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, train_input)\n",
    "    train_accuracy = compute_accuracy(preds, train_target)\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, test_input)\n",
    "    test_accuracy = compute_accuracy(preds, test_target)\n",
    "    print(f'{train_accuracy=}')\n",
    "    print(f'{test_accuracy=}')\n",
    "    return lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0, loss = 9660.6357421875\n",
      "step = 100, loss = 8209.51171875\n",
      "step = 200, loss = 7815.451171875\n",
      "step = 300, loss = 7545.455078125\n",
      "step = 400, loss = 7310.48486328125\n",
      "step = 500, loss = 7124.2080078125\n",
      "step = 600, loss = 6951.67529296875\n",
      "step = 700, loss = 6739.5146484375\n",
      "step = 800, loss = 6512.7626953125\n",
      "step = 900, loss = 6259.5556640625\n",
      "step = 1000, loss = 5817.6640625\n",
      "step = 1100, loss = 5047.923828125\n",
      "step = 1200, loss = 4802.81787109375\n",
      "step = 1300, loss = 4247.7841796875\n",
      "step = 1400, loss = 3799.70849609375\n",
      "step = 1500, loss = 3685.208740234375\n",
      "step = 1600, loss = 3483.32080078125\n",
      "step = 1700, loss = 3157.22265625\n",
      "step = 1800, loss = 3084.2724609375\n",
      "step = 1900, loss = 3017.005859375\n",
      "step = 2000, loss = 2939.00048828125\n",
      "step = 2100, loss = 2815.15771484375\n",
      "step = 2200, loss = 2471.42919921875\n",
      "step = 2300, loss = 2232.200439453125\n",
      "step = 2400, loss = 1957.146240234375\n",
      "step = 2500, loss = 1911.5325927734375\n",
      "step = 2600, loss = 1863.94482421875\n",
      "step = 2700, loss = 1808.98193359375\n",
      "step = 2800, loss = 1749.633056640625\n",
      "step = 2900, loss = 1673.793701171875\n",
      "step = 3000, loss = 1552.201904296875\n",
      "step = 3100, loss = 1257.173095703125\n",
      "step = 3200, loss = 695.051025390625\n",
      "step = 3300, loss = 470.349365234375\n",
      "step = 3400, loss = 450.7803039550781\n",
      "step = 3500, loss = 441.1287841796875\n",
      "step = 3600, loss = 433.8912048339844\n",
      "step = 3700, loss = 427.6289367675781\n",
      "step = 3800, loss = 422.30084228515625\n",
      "step = 3900, loss = 418.3131103515625\n",
      "step = 4000, loss = 415.1422119140625\n",
      "step = 4100, loss = 412.0663146972656\n",
      "step = 4200, loss = 409.09259033203125\n",
      "step = 4300, loss = 406.47119140625\n",
      "step = 4400, loss = 404.1275634765625\n",
      "step = 4500, loss = 401.8723449707031\n",
      "step = 4600, loss = 399.6646423339844\n",
      "step = 4700, loss = 397.50677490234375\n",
      "step = 4800, loss = 395.5967102050781\n",
      "step = 4900, loss = 393.926025390625\n",
      "step = 5000, loss = 392.3255615234375\n",
      "step = 5100, loss = 390.5713806152344\n",
      "step = 5200, loss = 388.8181457519531\n",
      "step = 5300, loss = 387.20330810546875\n",
      "step = 5400, loss = 385.7375183105469\n",
      "step = 5500, loss = 384.39202880859375\n",
      "step = 5600, loss = 383.0442810058594\n",
      "step = 5700, loss = 381.581787109375\n",
      "step = 5800, loss = 380.05615234375\n",
      "step = 5900, loss = 378.7141418457031\n",
      "step = 6000, loss = 377.4779968261719\n",
      "step = 6100, loss = 376.3186950683594\n",
      "step = 6200, loss = 375.2248229980469\n",
      "step = 6300, loss = 374.1664123535156\n",
      "step = 6400, loss = 373.1585693359375\n",
      "step = 6500, loss = 372.2301025390625\n",
      "step = 6600, loss = 371.3746337890625\n",
      "step = 6700, loss = 370.57281494140625\n",
      "step = 6800, loss = 369.8046569824219\n",
      "step = 6900, loss = 369.0596923828125\n",
      "step = 7000, loss = 368.3245849609375\n",
      "step = 7100, loss = 367.5819091796875\n",
      "step = 7200, loss = 366.80633544921875\n",
      "step = 7300, loss = 366.0101318359375\n",
      "step = 7400, loss = 365.16827392578125\n",
      "step = 7500, loss = 364.316650390625\n",
      "step = 7600, loss = 363.46502685546875\n",
      "step = 7700, loss = 362.6282958984375\n",
      "step = 7800, loss = 361.822509765625\n",
      "step = 7900, loss = 361.0397644042969\n",
      "step = 8000, loss = 360.28466796875\n",
      "step = 8100, loss = 359.53302001953125\n",
      "step = 8200, loss = 358.7655944824219\n",
      "step = 8300, loss = 357.9765930175781\n",
      "step = 8400, loss = 357.1881103515625\n",
      "step = 8500, loss = 356.4581298828125\n",
      "step = 8600, loss = 355.75506591796875\n",
      "step = 8700, loss = 355.04534912109375\n",
      "step = 8800, loss = 354.34375\n",
      "step = 8900, loss = 353.6544494628906\n",
      "step = 9000, loss = 353.00384521484375\n",
      "step = 9100, loss = 352.3977966308594\n",
      "step = 9200, loss = 351.7852783203125\n",
      "step = 9300, loss = 351.0582580566406\n",
      "step = 9400, loss = 350.3863830566406\n",
      "step = 9500, loss = 349.8186950683594\n",
      "step = 9600, loss = 349.2891540527344\n",
      "step = 9700, loss = 348.7711486816406\n",
      "step = 9800, loss = 348.248779296875\n",
      "step = 9900, loss = 347.65338134765625\n",
      "train_accuracy=0.8849999904632568\n",
      "test_accuracy=0.6150000095367432\n"
     ]
    }
   ],
   "source": [
    "lossi = train(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1285485e0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the same MLP layer but with fully pytorch code (nn.Linear(), etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network dimensions\n",
    "n_in = 784\n",
    "n_hidden = 200\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, Y_tr = train_input, train_target\n",
    "X_test, Y_test = test_input, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((\n",
    "            nn.Linear(784, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 10),\n",
    "            nn.Tanh()\n",
    "        ))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def __parameters__(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters]\n",
    "\n",
    "model = MLP()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =      0\tloss=0.14985\taccuracy (train, test): 0.08400\t0.23100\n",
      "step =   1000\tloss=0.00062\taccuracy (train, test): 1.00000\t0.85600\n",
      "step =   2000\tloss=0.00024\taccuracy (train, test): 1.00000\t0.84400\n",
      "step =   3000\tloss=0.00007\taccuracy (train, test): 1.00000\t0.83600\n",
      "step =   4000\tloss=0.00005\taccuracy (train, test): 1.00000\t0.83000\n",
      "step =   5000\tloss=0.00003\taccuracy (train, test): 1.00000\t0.83200\n",
      "step =   6000\tloss=0.00007\taccuracy (train, test): 1.00000\t0.83200\n",
      "step =   7000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.83100\n",
      "step =   8000\tloss=0.00003\taccuracy (train, test): 1.00000\t0.82900\n",
      "step =   9000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.82300\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 10000\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    y_pred = model(X_tr)\n",
    "    loss = loss_fn(y_pred, Y_tr)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if n % 1000 == 0: \n",
    "        with torch.no_grad():\n",
    "            # train accuracy\n",
    "            acc_train = compute_accuracy(y_pred, Y_tr)\n",
    "            # test accuracy\n",
    "            y_test_preds = model(X_test)\n",
    "            acc_test = compute_accuracy(y_test_preds, Y_test)\n",
    "            print(f'step = {n:6d}\\tloss={loss.item():.5f}\\taccuracy (train, test): {acc_train:.5f}\\t{acc_test:.5f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise: try to improve accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_with_Dropout(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((\n",
    "            nn.Linear(784, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.05), \n",
    "            nn.Linear(50, 10),\n",
    "            nn.Tanh()\n",
    "        ))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def __parameters__(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters]\n",
    "\n",
    "model_with_dropout = MLP_with_Dropout()\n",
    "optimizer = torch.optim.AdamW(model_with_dropout.parameters(), lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.8)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =      0\tloss=2.11839\taccuracy (train, test): 0.06300\t0.07500\n",
      "step =   1000\tloss=1.36298\taccuracy (train, test): 0.84500\t0.74400\n",
      "step =   2000\tloss=1.20509\taccuracy (train, test): 0.89900\t0.80100\n",
      "step =   3000\tloss=1.12193\taccuracy (train, test): 0.92700\t0.81300\n",
      "step =   4000\tloss=1.06733\taccuracy (train, test): 0.93800\t0.82800\n",
      "step =   5000\tloss=1.03080\taccuracy (train, test): 0.94900\t0.83800\n",
      "step =   6000\tloss=1.00234\taccuracy (train, test): 0.95500\t0.83500\n",
      "step =   7000\tloss=0.98094\taccuracy (train, test): 0.96200\t0.84400\n",
      "step =   8000\tloss=0.96634\taccuracy (train, test): 0.96400\t0.84300\n",
      "step =   9000\tloss=0.95323\taccuracy (train, test): 0.96600\t0.85600\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 10000\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    y_pred = model_with_dropout(X_tr)\n",
    "    loss = loss_fn(y_pred, Y_tr)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    if n % 1000 == 0: \n",
    "        with torch.no_grad():\n",
    "            # train accuracy\n",
    "            acc_train = compute_accuracy(y_pred, Y_tr)\n",
    "            # test accuracy\n",
    "            y_test_preds = model_with_dropout(X_test)\n",
    "            acc_test = compute_accuracy(y_test_preds, Y_test)\n",
    "            print(f'step = {n:6d}\\tloss={loss.item():.5f}\\taccuracy (train, test): {acc_train:.5f}\\t{acc_test:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slight dropout and replacing MSE Loss with Cross Entropy Loss, along with a scheduler that decreases the learning rate every 1000 epochs by a factor of gamma = 0.8, improve the model's performance. Accuracy increases from 0.823 to 0.856. Moreover, there is no more or at least reduced overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
